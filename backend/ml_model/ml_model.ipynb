{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "WuomncEtGMHs",
        "outputId": "676f9a0a-7b5e-4821-ba10-8a623fba4855"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-69ab7191-5b98-43f0-923d-05facac28240\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-69ab7191-5b98-43f0-923d-05facac28240\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving updated_job_matching_platform_dataset.xlsx to updated_job_matching_platform_dataset (1).xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Choose the updated_job_matching_platform_dataset.xlsx file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyV8KUOTGO2R",
        "outputId": "93eb28d0-4fa6-4bff-9b8b-8cb0d2c136f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "odu9ehpmGgfY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"updated_job_matching_platform_dataset.xlsx\"  # Replace with your uploaded file name\n",
        "user_data = pd.read_excel(file_path, sheet_name=\"user_data\")\n",
        "job_data = pd.read_excel(file_path, sheet_name=\"job_data\")\n",
        "interaction_data = pd.read_excel(file_path, sheet_name=\"interaction_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GoHyWlL0TS4s"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the interaction_data into training and testing sets (80/20 split)\n",
        "train_data, test_data = train_test_split(interaction_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the interaction matrix for the training set\n",
        "train_interaction_matrix = train_data.pivot_table(\n",
        "    index='User ID', columns='Job ID', values='Interaction Value', fill_value=0\n",
        ")\n",
        "\n",
        "# Save the user and job IDs for the training set\n",
        "train_user_ids = train_interaction_matrix.index.tolist()\n",
        "train_job_ids = train_interaction_matrix.columns.tolist()\n",
        "\n",
        "# For testing, we will keep the raw test_data as it is, to compare predicted values with actual values later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0D6kBKCGkFI",
        "outputId": "9ae24d54-e224-4c48-e8b7-fc1459440a3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   User ID                     Recommended Jobs\n",
            "0    US001  [JB016, JB025, JB003, JB030, JB023]\n",
            "1    US002  [JB030, JB028, JB015, JB029, JB013]\n",
            "2    US003  [JB010, JB011, JB012, JB024, JB022]\n",
            "3    US004  [JB029, JB028, JB030, JB013, JB008]\n",
            "4    US005  [JB020, JB019, JB021, JB018, JB016]\n",
            "5    US006  [JB028, JB030, JB013, JB029, JB015]\n",
            "6    US007  [JB018, JB026, JB016, JB017, JB025]\n",
            "7    US008  [JB010, JB012, JB011, JB015, JB019]\n",
            "8    US009  [JB018, JB016, JB026, JB017, JB027]\n",
            "9    US010  [JB013, JB030, JB028, JB014, JB015]\n",
            "10   US011  [JB018, JB016, JB017, JB026, JB025]\n",
            "11   US012  [JB016, JB018, JB017, JB026, JB025]\n",
            "12   US013  [JB018, JB016, JB026, JB017, JB027]\n",
            "13   US014  [JB030, JB015, JB028, JB010, JB013]\n",
            "14   US015  [JB030, JB013, JB028, JB029, JB014]\n",
            "15   US016  [JB030, JB015, JB028, JB013, JB014]\n",
            "16   US017  [JB004, JB006, JB005, JB018, JB017]\n",
            "17   US018  [JB004, JB006, JB005, JB008, JB019]\n",
            "18   US019  [JB004, JB005, JB006, JB022, JB023]\n",
            "19   US020  [JB010, JB012, JB011, JB015, JB028]\n",
            "20   US021  [JB010, JB011, JB012, JB024, JB019]\n",
            "21   US022  [JB010, JB011, JB012, JB005, JB004]\n",
            "22   US023  [JB026, JB027, JB025, JB019, JB023]\n",
            "23   US024  [JB023, JB024, JB022, JB029, JB001]\n",
            "24   US025  [JB026, JB027, JB025, JB023, JB022]\n",
            "25   US026  [JB003, JB002, JB001, JB022, JB023]\n",
            "26   US027  [JB002, JB003, JB023, JB024, JB022]\n",
            "27   US028  [JB002, JB003, JB001, JB013, JB014]\n",
            "28   US029  [JB003, JB002, JB001, JB023, JB022]\n",
            "29   US030  [JB021, JB019, JB020, JB009, JB007]\n",
            "30   US031  [JB030, JB013, JB028, JB029, JB003]\n",
            "31   US032  [JB023, JB024, JB022, JB028, JB013]\n"
          ]
        }
      ],
      "source": [
        "# Content-Based Filtering Implementation\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the datasets\n",
        "user_data = pd.read_excel(\"updated_job_matching_platform_dataset.xlsx\", sheet_name=\"user_data\")\n",
        "job_data = pd.read_excel(\"updated_job_matching_platform_dataset.xlsx\", sheet_name=\"job_data\")\n",
        "\n",
        "# Step 1: Combine textual features into a single field\n",
        "user_data['Profile'] = (\n",
        "    user_data['Skills'].fillna('') + ' ' +\n",
        "    user_data['Interests'].fillna('') + ' ' +\n",
        "    user_data['Previous Jobs'].fillna('') + ' ' +\n",
        "    user_data['Looking Jobs'].fillna('') + ' ' +\n",
        "    user_data['Description'].fillna('')\n",
        ")\n",
        "\n",
        "job_data['Details'] = (\n",
        "    job_data['Job Title'].fillna('') + ' ' +\n",
        "    job_data['Skills Required'].fillna('') + ' ' +\n",
        "    job_data['Experience Required'].fillna('') + ' ' +\n",
        "    job_data['Job Description'].fillna('')\n",
        ")\n",
        "\n",
        "# Step 2: Vectorize text data using a unified vocabulary\n",
        "combined_text = pd.concat([user_data['Profile'], job_data['Details']], axis=0)\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
        "tfidf_matrix = tfidf.fit_transform(combined_text)\n",
        "\n",
        "# Split the combined matrix back into user and job matrices\n",
        "user_tfidf = tfidf_matrix[:len(user_data)]\n",
        "job_tfidf = tfidf_matrix[len(user_data):]\n",
        "\n",
        "# Step 3: Compute cosine similarity between users and jobs\n",
        "similarity_matrix = cosine_similarity(user_tfidf, job_tfidf)\n",
        "\n",
        "# Step 4: Generate recommendations\n",
        "# Create a DataFrame to store recommendations\n",
        "recommendations = []\n",
        "\n",
        "for user_idx, user_id in enumerate(user_data['User ID']):\n",
        "    # Get similarity scores for the user\n",
        "    similarity_scores = list(enumerate(similarity_matrix[user_idx]))\n",
        "\n",
        "    # Sort jobs by similarity scores (descending order)\n",
        "    sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the top 5 recommended jobs for this user\n",
        "    top_jobs = [job_data.iloc[job_idx]['Job ID'] for job_idx, score in sorted_scores[:5]]\n",
        "\n",
        "    # Store recommendations\n",
        "    recommendations.append({\"User ID\": user_id, \"Recommended Jobs\": top_jobs})\n",
        "\n",
        "# Convert recommendations to a DataFrame for better visualization\n",
        "recommendations_df = pd.DataFrame(recommendations)\n",
        "\n",
        "# Display recommendations\n",
        "print(recommendations_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2afkeh1IeZb",
        "outputId": "ef603234-39e1-4925-da86-c454c2b79c24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommendations saved to content_based_recommendations.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Save recommendations to an Excel file\n",
        "recommendations_df.to_excel(\"content_based_recommendations.xlsx\", index=False)\n",
        "print(\"Recommendations saved to content_based_recommendations.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "1bwZOHODIjqd",
        "outputId": "5e0a1f1e-e68a-4f20-bbd9-2945942a6849"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_cf5677e4-fa75-41f9-a6d7-b133d70adf9c\", \"content_based_recommendations.xlsx\", 5612)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"content_based_recommendations.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSgBR0EqJZk3",
        "outputId": "21b40a25-9948-45d3-d495-476ba2b73453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   User ID                       Recommended Jobs\n",
            "0    US001    [JB016, JB018, JB017, JB020, JB003]\n",
            "1    US002    [JB028, JB030, JB029, JB011, JB010]\n",
            "2    US003    [JB010, JB023, JB012, JB011, JB022]\n",
            "3    US004    [JB029, JB030, JB028, JB007, JB009]\n",
            "4    US005  [JB020, JB0019, JB021, JB0017, JB018]\n",
            "5    US006    [JB028, JB030, JB029, JB018, JB001]\n",
            "6    US007  [JB025, JB026, JB0017, JB0016, JB027]\n",
            "7    US008    [JB012, JB011, JB010, JB024, JB023]\n",
            "8    US009    [JB018, JB017, JB016, JB021, JB020]\n",
            "9    US010    [JB008, JB006, JB009, JB005, JB007]\n",
            "10   US011    [JB026, JB017, JB019, JB021, JB027]\n",
            "11   US012    [JB026, JB016, JB021, JB020, JB027]\n",
            "12   US013    [JB019, JB025, JB006, JB005, JB026]\n",
            "13   US014    [JB013, JB011, JB014, JB010, JB012]\n",
            "14   US015    [JB030, JB013, JB014, JB015, JB029]\n",
            "15   US016    [JB014, JB029, JB030, JB028, JB013]\n",
            "16   US017    [JB004, JB016, JB005, JB006, JB018]\n",
            "17   US018    [JB005, JB008, JB009, JB007, JB006]\n",
            "18   US019    [JB007, JB006, JB008, JB004, JB023]\n",
            "19   US020    [JB015, JB014, JB013, JB011, JB010]\n",
            "20   US021    [JB011, JB012, JB010, JB023, JB024]\n",
            "21   US022    [JB011, JB012, JB010, JB023, JB024]\n",
            "22   US023    [JB027, JB026, JB019, JB021, JB020]\n",
            "23   US024    [JB003, JB002, JB001, JB024, JB022]\n",
            "24   US025    [JB027, JB026, JB025, JB024, JB004]\n",
            "25   US026    [JB001, JB024, JB003, JB023, JB002]\n",
            "26   US027    [JB023, JB024, JB022, JB002, JB001]\n",
            "27   US028    [JB002, JB003, JB001, JB008, JB030]\n",
            "28   US029    [JB024, JB003, JB001, JB002, JB022]\n",
            "29   US030    [JB020, JB021, JB019, JB009, JB007]\n",
            "30   US031    [JB003, JB002, JB001, JB030, JB028]\n",
            "31   US032    [JB022, JB023, JB024, JB010, JB014]\n"
          ]
        }
      ],
      "source": [
        "# Collaborative Filtering Implementation\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Prepare the interaction matrix\n",
        "interaction_matrix = interaction_data.pivot_table(\n",
        "    index='User ID', columns='Job ID', values='Interaction Value', fill_value=0\n",
        ")\n",
        "\n",
        "# Save the user and job IDs for reference\n",
        "user_ids = interaction_matrix.index.tolist()\n",
        "job_ids = interaction_matrix.columns.tolist()\n",
        "\n",
        "# Step 2: Apply SVD for Matrix Factorization\n",
        "# Adjust n_components dynamically based on the number of jobs\n",
        "n_components = min(33, interaction_matrix.shape[1])  # Adjust to the number of jobs\n",
        "\n",
        "# Decompose the interaction matrix\n",
        "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
        "latent_matrix = svd.fit_transform(interaction_matrix)\n",
        "\n",
        "# Reconstruct the predicted interaction matrix\n",
        "predicted_matrix = np.dot(latent_matrix, svd.components_)\n",
        "\n",
        "# Step 3: Generate Recommendations\n",
        "# Create a DataFrame for the predicted matrix\n",
        "predicted_df = pd.DataFrame(predicted_matrix, index=train_user_ids, columns=train_job_ids)\n",
        "\n",
        "# Generate top recommendations for each user\n",
        "collab_recommendations = []\n",
        "\n",
        "for user_id in user_ids:\n",
        "    # Get the predicted scores for this user\n",
        "    user_scores = predicted_df.loc[user_id].sort_values(ascending=False)\n",
        "\n",
        "    # Get the top 5 recommended jobs\n",
        "    top_jobs = user_scores.head(5).index.tolist()\n",
        "\n",
        "    # Store recommendations\n",
        "    collab_recommendations.append({\"User ID\": user_id, \"Recommended Jobs\": top_jobs})\n",
        "\n",
        "# Convert recommendations to a DataFrame\n",
        "collab_recommendations_df = pd.DataFrame(collab_recommendations)\n",
        "\n",
        "# Display recommendations\n",
        "print(collab_recommendations_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4_XCZ3OJ6x5",
        "outputId": "03a1ede7-b7cd-4505-a120-ed1af883c850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collaborative recommendations saved to collaborative_recommendations.xlsx\n"
          ]
        }
      ],
      "source": [
        "collab_recommendations_df.to_excel(\"collaborative_recommendations.xlsx\", index=False)\n",
        "print(\"Collaborative recommendations saved to collaborative_recommendations.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WbGxUTJLK5qo",
        "outputId": "7fcd3bb3-309b-478d-86cb-f55ae3712a84"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_ddae8f4e-8014-4b3b-affa-274c90a2df86\", \"collaborative_recommendations.xlsx\", 5650)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"collaborative_recommendations.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YKi3kB5LCef",
        "outputId": "2cedad30-3c55-43d2-f1d7-424a1a03a4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hybrid recommendations saved to hybrid_recommendations.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Hybrid Model\n",
        "\n",
        "# Step 1: Normalize Scores\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalize content-based scores\n",
        "content_scores = similarity_matrix.copy()\n",
        "scaler = MinMaxScaler()\n",
        "content_scores = scaler.fit_transform(content_scores)\n",
        "\n",
        "# Normalize collaborative filtering scores\n",
        "collab_scores = predicted_matrix.copy()\n",
        "collab_scores = scaler.fit_transform(collab_scores)\n",
        "\n",
        "# Step 2: Identify Common Job IDs\n",
        "# Find the intersection of job IDs between job_data and interaction_data\n",
        "common_job_ids = list(set(job_data['Job ID']).intersection(set(job_ids)))\n",
        "\n",
        "# Filter job IDs to ensure alignment with the matrices\n",
        "job_indices_content = [list(job_data['Job ID']).index(job_id) for job_id in common_job_ids]\n",
        "job_indices_collab = [job_ids.index(job_id) for job_id in common_job_ids]\n",
        "\n",
        "# Step 3: Filter Scores Matrices to Include Only Common Jobs\n",
        "# Filter content-based and collaborative scores\n",
        "content_scores_filtered = content_scores[:, job_indices_content]\n",
        "collab_scores_filtered = collab_scores[:, job_indices_collab]\n",
        "\n",
        "# Ensure both matrices are aligned\n",
        "assert content_scores_filtered.shape == collab_scores_filtered.shape, \"Matrices do not align!\"\n",
        "\n",
        "# Step 4: Compute Hybrid Scores\n",
        "# Define weights for content-based and collaborative filtering\n",
        "content_weight = 0.5\n",
        "collab_weight = 0.5\n",
        "\n",
        "# Calculate the hybrid score\n",
        "hybrid_scores = (content_weight * content_scores_filtered) + (collab_weight * collab_scores_filtered)\n",
        "\n",
        "# Step 5: Generate Recommendations\n",
        "hybrid_recommendations = []\n",
        "\n",
        "for user_idx, user_id in enumerate(user_ids):\n",
        "    # Get hybrid scores for this user\n",
        "    user_hybrid_scores = hybrid_scores[user_idx]\n",
        "\n",
        "    # Rank jobs by hybrid scores\n",
        "    sorted_jobs = sorted(\n",
        "        enumerate(user_hybrid_scores),\n",
        "        key=lambda x: x[1],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    # Get the top 5 recommended jobs\n",
        "    top_jobs = [common_job_ids[job_idx] for job_idx, score in sorted_jobs[:5]]\n",
        "\n",
        "    # Store recommendations\n",
        "    hybrid_recommendations.append({\"User ID\": user_id, \"Recommended Jobs\": top_jobs})\n",
        "\n",
        "# Convert recommendations to a DataFrame\n",
        "hybrid_recommendations_df = pd.DataFrame(hybrid_recommendations)\n",
        "\n",
        "# Step 6: Save Recommendations\n",
        "hybrid_recommendations_df.to_excel(\"hybrid_recommendations.xlsx\", index=False)\n",
        "print(\"Hybrid recommendations saved to hybrid_recommendations.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MtJS_W9-LR6o",
        "outputId": "d75ac089-7e1b-4ed1-fddd-bcf46c460c84"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_919a4d85-b066-419b-8744-cec36782e7a9\", \"hybrid_recommendations.xlsx\", 5649)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"hybrid_recommendations.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R69oEX5fM1LC",
        "outputId": "a03bd276-e8ca-4542-e6c2-58066ddc684a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision@5: 0.2800\n",
            "Recall@5: 0.8000\n"
          ]
        }
      ],
      "source": [
        "# Testing and Evaluating the Model\n",
        "\n",
        "# Step 1: Prepare the Testing Interaction Matrix\n",
        "# Create a pivot table for the testing set\n",
        "test_interactions = test_data.pivot_table(\n",
        "    index='User ID', columns='Job ID', values='Interaction Value', fill_value=0\n",
        ")\n",
        "\n",
        "# Step 2: Align Predicted and Testing Data\n",
        "# Find common users and jobs between predicted_df and test_interactions\n",
        "common_users = list(set(predicted_df.index).intersection(set(test_interactions.index)))\n",
        "common_jobs = list(set(predicted_df.columns).intersection(set(test_interactions.columns)))\n",
        "\n",
        "# Filter predicted_df and test_interactions to include only common users and jobs\n",
        "predicted_df_filtered = predicted_df.loc[common_users, common_jobs]\n",
        "test_interactions_filtered = test_interactions.loc[common_users, common_jobs]\n",
        "\n",
        "# Step 3: Define Precision@K and Recall@K Functions\n",
        "def precision_at_k(predictions, actual, k=5):\n",
        "    precision_scores = []\n",
        "    for user in predictions.index:\n",
        "        if user not in actual.index:\n",
        "            continue  # Skip users who are not in the actual data\n",
        "        # Get the top K predictions\n",
        "        top_k_predictions = predictions.loc[user].sort_values(ascending=False).head(k).index\n",
        "        # Get the actual jobs for this user\n",
        "        actual_jobs = actual.loc[user][actual.loc[user] > 0].index\n",
        "        # Calculate precision\n",
        "        hits = len(set(top_k_predictions).intersection(set(actual_jobs)))\n",
        "        precision_scores.append(hits / k)\n",
        "    return sum(precision_scores) / len(precision_scores) if precision_scores else 0\n",
        "\n",
        "def recall_at_k(predictions, actual, k=5):\n",
        "    recall_scores = []\n",
        "    for user in predictions.index:\n",
        "        if user not in actual.index:\n",
        "            continue  # Skip users who are not in the actual data\n",
        "        # Get the top K predictions\n",
        "        top_k_predictions = predictions.loc[user].sort_values(ascending=False).head(k).index\n",
        "        # Get the actual jobs for this user\n",
        "        actual_jobs = actual.loc[user][actual.loc[user] > 0].index\n",
        "        # Calculate recall\n",
        "        hits = len(set(top_k_predictions).intersection(set(actual_jobs)))\n",
        "        recall_scores.append(hits / len(actual_jobs) if len(actual_jobs) > 0 else 0)\n",
        "    return sum(recall_scores) / len(recall_scores) if recall_scores else 0\n",
        "\n",
        "# Step 4: Evaluate Precision@K and Recall@K\n",
        "precision = precision_at_k(predicted_df_filtered, test_interactions_filtered, k=5)\n",
        "recall = recall_at_k(predicted_df_filtered, test_interactions_filtered, k=5)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Precision@5: {precision:.4f}\")\n",
        "print(f\"Recall@5: {recall:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exnDmFYQWNTm",
        "outputId": "7cf8b61b-c56e-4a3d-fdbd-08ff55da604d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top recommended jobs for the new user:\n",
            "['JB018', 'JB016', 'JB017', 'JB002', 'JB020']\n"
          ]
        }
      ],
      "source": [
        "# Making Predictions with New Data\n",
        "\n",
        "# Step 1: Add a New User Profile (Example)\n",
        "new_user_profile = {\n",
        "    \"Skills\": \"Cooking, Cleaning, Teamwork\",\n",
        "    \"Interests\": \"Hospitality, Organization\",\n",
        "    \"Previous Jobs\": \"Housemaid\",\n",
        "    \"Looking Jobs\": \"Waiter, Babysitter\",\n",
        "    \"Description\": \"Experienced housemaid looking for new opportunities.\"\n",
        "}\n",
        "\n",
        "# Combine new user data into a single profile\n",
        "new_user_text = (\n",
        "    new_user_profile['Skills'] + ' ' +\n",
        "    new_user_profile['Interests'] + ' ' +\n",
        "    new_user_profile['Previous Jobs'] + ' ' +\n",
        "    new_user_profile['Looking Jobs'] + ' ' +\n",
        "    new_user_profile['Description']\n",
        ")\n",
        "\n",
        "# Step 2: Compute Similarity with Existing Jobs (Content-Based)\n",
        "new_user_vector = tfidf.transform([new_user_text])  # Transform new user profile into TF-IDF vector\n",
        "new_user_similarities = cosine_similarity(new_user_vector, job_tfidf).flatten()  # Calculate similarity\n",
        "\n",
        "# Step 3: Recommend Top 5 Jobs\n",
        "top_jobs_for_new_user = [job_data.iloc[i]['Job ID'] for i in new_user_similarities.argsort()[-5:][::-1]]\n",
        "\n",
        "print(\"Top recommended jobs for the new user:\")\n",
        "print(top_jobs_for_new_user)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq1KEK1UYRBg",
        "outputId": "e275b3e0-7189-4c4f-dc0f-c9f8e8ca3341"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Root Mean Squared Error (RMSE): 0.0000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Flatten the filtered test_interactions and predicted_df_filtered for comparison\n",
        "actual_values = test_interactions_filtered.values.flatten()\n",
        "predicted_values = predicted_df_filtered.values.flatten()\n",
        "\n",
        "# Only consider non-zero actual values to avoid comparing irrelevant pairs\n",
        "non_zero_indices = actual_values > 0\n",
        "actual_values_non_zero = actual_values[non_zero_indices]\n",
        "predicted_values_non_zero = predicted_values[non_zero_indices]\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(actual_values_non_zero, predicted_values_non_zero))\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6FLwdn7a7bb",
        "outputId": "16966257-760a-4bcd-8c0b-ed0accdd2544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Model Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Set a threshold for considering a prediction as relevant\n",
        "threshold = 0.5\n",
        "\n",
        "# Flatten the testing and predicted matrices\n",
        "actual_values = test_interactions_filtered.values.flatten()\n",
        "predicted_values = predicted_df_filtered.values.flatten()\n",
        "\n",
        "# Only consider non-zero actual values\n",
        "non_zero_indices = actual_values > 0\n",
        "actual_values_non_zero = actual_values[non_zero_indices]\n",
        "predicted_values_non_zero = predicted_values[non_zero_indices]\n",
        "\n",
        "# Apply the threshold to predicted values\n",
        "predicted_classes = (predicted_values_non_zero >= threshold).astype(int)\n",
        "actual_classes = (actual_values_non_zero >= threshold).astype(int)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_predictions = (predicted_classes == actual_classes).sum()\n",
        "total_predictions = len(actual_classes)\n",
        "accuracy = (correct_predictions / total_predictions) * 100\n",
        "\n",
        "print(f\"Overall Model Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN6Vvf8haRJi",
        "outputId": "524bce50-50a4-4da0-c8b0-1a37ea69c48d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy at threshold 0.4: 100.00%\n",
            "Accuracy at threshold 0.5: 100.00%\n",
            "Accuracy at threshold 0.6: 100.00%\n",
            "Accuracy at threshold 0.7: 100.00%\n"
          ]
        }
      ],
      "source": [
        "for threshold in [0.4, 0.5, 0.6, 0.7]:\n",
        "    predicted_classes = (predicted_values_non_zero >= threshold).astype(int)\n",
        "    accuracy = (predicted_classes == actual_classes).mean() * 100\n",
        "    print(f\"Accuracy at threshold {threshold}: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_djI7dybw21",
        "outputId": "dd46898e-bfa5-4331-8756-c2269516680e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model components have been saved!\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the TF-IDF vectorizer\n",
        "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tfidf, f)\n",
        "\n",
        "# Save the collaborative filtering components (SVD)\n",
        "with open(\"svd_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(svd, f)\n",
        "\n",
        "# Save the predicted matrix (optional, for quick lookup in the web app)\n",
        "predicted_df_filtered.to_pickle(\"predicted_matrix.pkl\")\n",
        "\n",
        "print(\"Model components have been saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JlfbsGqYb3nX",
        "outputId": "55fe9dde-83af-47a9-ab5b-e67d491e9dbf"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_87713095-9037-42ce-9be6-e8212db4e56e\", \"tfidf_vectorizer.pkl\", 10258)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a423ac36-8109-4f7d-a174-1481ffcb262a\", \"svd_model.pkl\", 10153)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_5012d0c1-fdff-47b6-9bce-bc7adbaa0c51\", \"predicted_matrix.pkl\", 6670)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the saved files\n",
        "files.download(\"tfidf_vectorizer.pkl\")\n",
        "files.download(\"svd_model.pkl\")\n",
        "files.download(\"predicted_matrix.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgguBouxcQ32"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
